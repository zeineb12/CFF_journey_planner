{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from datetime import *\n",
    "import ast\n",
    "from pyspark.sql.types import *\n",
    "import itertools\n",
    "from functools import reduce\n",
    "import math\n",
    "from collections import Counter\n",
    "from dateutil.parser import parse\n",
    "from geopy import distance\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import networkx as nx\n",
    "import os\n",
    "import getpass\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import regexp_replace, col\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://iccluster042.iccluster.epfl.ch:4050\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.2.3.1.0.0-78</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>scheduler-sbenhass</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=scheduler-sbenhass>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = pyspark.conf.SparkConf()\n",
    "conf.setMaster('yarn')\n",
    "conf.setAppName('scheduler-{0}'.format(getpass.getuser()))\n",
    "conf.set('spark.executor.memory', '8g')\n",
    "conf.set('spark.executor.instances', '16')\n",
    "conf.set('spark.port.maxRetries', '100')\n",
    "sc = pyspark.SparkContext.getOrCreate(conf)\n",
    "conf = sc.getConf()\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_name = 'Zürich HB'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data\n",
    "\n",
    "In this section we read the sbb data and rename all columns in english for the sake of readability. We also filter out trips that do not contain actual time of arrival or departure.\n",
    "\n",
    "NB : We chose to build our model based on the schedule of April 2018. When trying more recent months, we figured out that there was often no measure of actual arrival or departure times (prognose_status != 'GESCHAETZT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_all = spark.read.option(\"header\", \"true\").csv(\"/datasets/sbb/2019/01/2019-01-23istdaten.csv.bz2\", sep= ';')\n",
    "\n",
    "# Using only april 2018 dataset, to get the full dataset uncomment first line\n",
    "df = spark.read.option(\"header\", \"true\").csv(\"/datasets/sbb/2018/04/*\", sep= ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed('BETRIEBSTAG', 'date').\\\n",
    "withColumnRenamed('FAHRT_BEZEICHNER', 'trip_id').\\\n",
    "withColumnRenamed('LINIEN_ID', 'train_id').\\\n",
    "withColumnRenamed('BPUIC', 'BPUIC').\\\n",
    "withColumnRenamed('HALTESTELLEN_NAME', 'stop_name').\\\n",
    "withColumnRenamed('ANKUNFTSZEIT', 'arrival_time').\\\n",
    "withColumnRenamed('AN_PROGNOSE', 'actual_arrival_time').\\\n",
    "withColumnRenamed('AN_PROGNOSE_STATUS', 'an_prognose_status').\\\n",
    "withColumnRenamed('ABFAHRTSZEIT', 'departure_time').\\\n",
    "withColumnRenamed('AB_PROGNOSE', 'actual_departure_time').\\\n",
    "withColumnRenamed('AB_PROGNOSE_STATUS', 'ab_prognose_status').\\\n",
    "drop('BETREIBER_ID','LINIEN_TEXT','ZUSATZFAHRT_TF','FAELLT_AUS_TF', 'BETREIBER_ABK', 'BETREIBER_NAME', 'PRODUKT_ID', 'UMLAUF_ID', 'VERKEHRSMITTEL_TEXT','DURCHFAHRT_TF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Filter out trips where there is no measure of actual time of arrival\n",
    "df = df.filter(df.an_prognose_status==\"GESCHAETZT\")\n",
    "df = df.filter(df.ab_prognose_status==\"GESCHAETZT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('an_prognose_status','ab_prognose_status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>train_id</th>\n",
       "      <th>BPUIC</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>actual_arrival_time</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>actual_departure_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.04.2018</td>\n",
       "      <td>80:80DBR_:3040:000</td>\n",
       "      <td>3040</td>\n",
       "      <td>8503424</td>\n",
       "      <td>Schaffhausen</td>\n",
       "      <td>20.04.2018 08:14</td>\n",
       "      <td>20.04.2018 08:15:48</td>\n",
       "      <td>20.04.2018 08:16</td>\n",
       "      <td>20.04.2018 08:17:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.04.2018</td>\n",
       "      <td>80:80DBR_:3041:000</td>\n",
       "      <td>3041</td>\n",
       "      <td>8503424</td>\n",
       "      <td>Schaffhausen</td>\n",
       "      <td>20.04.2018 07:42</td>\n",
       "      <td>20.04.2018 07:41:49</td>\n",
       "      <td>20.04.2018 07:43</td>\n",
       "      <td>20.04.2018 07:43:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.04.2018</td>\n",
       "      <td>80:80DBR_:3042:000</td>\n",
       "      <td>3042</td>\n",
       "      <td>8503424</td>\n",
       "      <td>Schaffhausen</td>\n",
       "      <td>20.04.2018 10:14</td>\n",
       "      <td>20.04.2018 10:17:37</td>\n",
       "      <td>20.04.2018 10:16</td>\n",
       "      <td>20.04.2018 10:18:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.04.2018</td>\n",
       "      <td>80:80DBR_:3043:000</td>\n",
       "      <td>3043</td>\n",
       "      <td>8503424</td>\n",
       "      <td>Schaffhausen</td>\n",
       "      <td>20.04.2018 09:42</td>\n",
       "      <td>20.04.2018 09:41:42</td>\n",
       "      <td>20.04.2018 09:43</td>\n",
       "      <td>20.04.2018 09:43:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.04.2018</td>\n",
       "      <td>80:80DBR_:3044:000</td>\n",
       "      <td>3044</td>\n",
       "      <td>8503424</td>\n",
       "      <td>Schaffhausen</td>\n",
       "      <td>20.04.2018 12:14</td>\n",
       "      <td>20.04.2018 12:15:26</td>\n",
       "      <td>20.04.2018 12:16</td>\n",
       "      <td>20.04.2018 12:16:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date             trip_id train_id    BPUIC     stop_name  \\\n",
       "0  20.04.2018  80:80DBR_:3040:000     3040  8503424  Schaffhausen   \n",
       "1  20.04.2018  80:80DBR_:3041:000     3041  8503424  Schaffhausen   \n",
       "2  20.04.2018  80:80DBR_:3042:000     3042  8503424  Schaffhausen   \n",
       "3  20.04.2018  80:80DBR_:3043:000     3043  8503424  Schaffhausen   \n",
       "4  20.04.2018  80:80DBR_:3044:000     3044  8503424  Schaffhausen   \n",
       "\n",
       "       arrival_time  actual_arrival_time    departure_time  \\\n",
       "0  20.04.2018 08:14  20.04.2018 08:15:48  20.04.2018 08:16   \n",
       "1  20.04.2018 07:42  20.04.2018 07:41:49  20.04.2018 07:43   \n",
       "2  20.04.2018 10:14  20.04.2018 10:17:37  20.04.2018 10:16   \n",
       "3  20.04.2018 09:42  20.04.2018 09:41:42  20.04.2018 09:43   \n",
       "4  20.04.2018 12:14  20.04.2018 12:15:26  20.04.2018 12:16   \n",
       "\n",
       "  actual_departure_time  \n",
       "0   20.04.2018 08:17:31  \n",
       "1   20.04.2018 07:43:51  \n",
       "2   20.04.2018 10:18:49  \n",
       "3   20.04.2018 09:43:41  \n",
       "4   20.04.2018 12:16:51  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coordinates\n",
    "\n",
    "In this section we read the metadata file and keep only the columns we are interested in. This will be used it in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BPUIC</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>altitude</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000002</td>\n",
       "      <td>26.074412</td>\n",
       "      <td>44.446770</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Bucuresti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000003</td>\n",
       "      <td>1.811446</td>\n",
       "      <td>50.901549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Calais</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000004</td>\n",
       "      <td>1.075329</td>\n",
       "      <td>51.284212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Canterbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000005</td>\n",
       "      <td>-3.543547</td>\n",
       "      <td>50.729172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Exeter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000007</td>\n",
       "      <td>9.733756</td>\n",
       "      <td>46.922368</td>\n",
       "      <td>744.0</td>\n",
       "      <td>Fideris, Bahnhof</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     BPUIC       long        lat  altitude              name\n",
       "0  0000002  26.074412  44.446770       0.0         Bucuresti\n",
       "1  0000003   1.811446  50.901549       0.0            Calais\n",
       "2  0000004   1.075329  51.284212       0.0        Canterbury\n",
       "3  0000005  -3.543547  50.729172       0.0            Exeter\n",
       "4  0000007   9.733756  46.922368     744.0  Fideris, Bahnhof"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['BPUIC','long','lat','altitude','name']\n",
    "\n",
    "coordinates = pd.read_csv('BFKOORD_GEO',sep='\\t', header=None)\n",
    "\n",
    "coordinates[0] = coordinates[0].apply(lambda x : x.split())\n",
    "for i in range(4):\n",
    "    if i == 0:\n",
    "        coordinates[cols[i]] = coordinates[0].apply(lambda x : x[i])\n",
    "    else :\n",
    "        coordinates[cols[i]] = coordinates[0].apply(lambda x : float(x[i]))\n",
    "\n",
    "coordinates[cols[-1]] = coordinates[0].apply(lambda x : \" \".join(x[5:]))\n",
    "\n",
    "coordinates = coordinates.drop(columns=[0])\n",
    "coordinates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Data\n",
    "\n",
    "In this section we will filter out the stops that are outside the radius of 10 km from the starting station Zürich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(row):\n",
    "    point = (row['lat'],row['long'],row['altitude'])\n",
    "    return distance.distance(point,start_coord).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BPUIC</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "      <th>altitude</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>8503000</td>\n",
       "      <td>8.540192</td>\n",
       "      <td>47.378177</td>\n",
       "      <td>408.0</td>\n",
       "      <td>Zürich HB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        BPUIC      long        lat  altitude       name\n",
       "2379  8503000  8.540192  47.378177     408.0  Zürich HB"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coordinates[coordinates['name'] == stop_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_coord = coordinates[coordinates['name'] == stop_name]\n",
    "start_coord = (start_coord['lat'].values[0],start_coord['long'].values[0],start_coord['altitude'].values[0])\n",
    "\n",
    "# Get the distance from each stop to start\n",
    "coordinates['distance_to_start_km'] = coordinates.apply(calculate_distance, axis=1)\n",
    "\n",
    "# Keep only stops that are within 10 km of start\n",
    "coordinates = coordinates[coordinates.distance_to_start_km <= 10]\n",
    "reachable_stops_id = list(coordinates.BPUIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Keep only stops that are within a radius of 10 km of start\n",
    "df = df.filter(df.BPUIC.isin(reachable_stops_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------+-------+----------------+----------------+-------------------+----------------+---------------------+\n",
      "|date      |trip_id       |train_id|BPUIC  |stop_name       |arrival_time    |actual_arrival_time|departure_time  |actual_departure_time|\n",
      "+----------+--------------+--------+-------+----------------+----------------+-------------------+----------------+---------------------+\n",
      "|20.04.2018|85:11:1255:001|1255    |8503000|Zürich HB       |20.04.2018 08:26|20.04.2018 08:27:41|20.04.2018 08:37|20.04.2018 08:39:43  |\n",
      "|20.04.2018|85:11:1258:001|1258    |8503000|Zürich HB       |20.04.2018 21:23|20.04.2018 21:25:19|20.04.2018 21:34|20.04.2018 21:34:51  |\n",
      "|20.04.2018|85:11:1507:002|1507    |8503000|Zürich HB       |20.04.2018 06:30|20.04.2018 06:30:14|20.04.2018 06:39|20.04.2018 06:39:52  |\n",
      "|20.04.2018|85:11:1507:002|1507    |8503016|Zürich Flughafen|20.04.2018 06:49|20.04.2018 06:49:43|20.04.2018 06:51|20.04.2018 06:52:01  |\n",
      "|20.04.2018|85:11:1509:003|1509    |8503000|Zürich HB       |20.04.2018 07:30|20.04.2018 07:31:24|20.04.2018 07:39|20.04.2018 07:39:36  |\n",
      "+----------+--------------+--------+-------+----------------+----------------+-------------------+----------------+---------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by Trip id \n",
    "\n",
    "**In this section we will try to recover all the itineraries by grouping all rows over Trip ID. Since we are working with a whole month (for the sake of completeness), we will get the same patterns again and again. We will then filter the duplicates and keep only single daily itineraries.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_date(date):\n",
    "    \"\"\"This function keeps only time from a given date\"\"\"\n",
    "    if date:\n",
    "        return date.split()[1]\n",
    "    else:\n",
    "        return None\n",
    "remove_date_udf = F.udf(remove_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In the next cell, we added a column stop_dt_at (stop, departure time, arrival time) to have data in a more concise form.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------+-------+----------------+------------+-------------------+--------------+---------------------+--------------------------------+\n",
      "|date      |trip_id       |train_id|BPUIC  |stop_name       |arrival_time|actual_arrival_time|departure_time|actual_departure_time|stop_dt_at                      |\n",
      "+----------+--------------+--------+-------+----------------+------------+-------------------+--------------+---------------------+--------------------------------+\n",
      "|20.04.2018|85:11:1255:001|1255    |8503000|Zürich HB       |08:26       |20.04.2018 08:27:41|08:37         |20.04.2018 08:39:43  |[Zürich HB, 08:26, 08:37]       |\n",
      "|20.04.2018|85:11:1258:001|1258    |8503000|Zürich HB       |21:23       |20.04.2018 21:25:19|21:34         |20.04.2018 21:34:51  |[Zürich HB, 21:23, 21:34]       |\n",
      "|20.04.2018|85:11:1507:002|1507    |8503000|Zürich HB       |06:30       |20.04.2018 06:30:14|06:39         |20.04.2018 06:39:52  |[Zürich HB, 06:30, 06:39]       |\n",
      "|20.04.2018|85:11:1507:002|1507    |8503016|Zürich Flughafen|06:49       |20.04.2018 06:49:43|06:51         |20.04.2018 06:52:01  |[Zürich Flughafen, 06:49, 06:51]|\n",
      "|20.04.2018|85:11:1509:003|1509    |8503000|Zürich HB       |07:30       |20.04.2018 07:31:24|07:39         |20.04.2018 07:39:36  |[Zürich HB, 07:30, 07:39]       |\n",
      "+----------+--------------+--------+-------+----------------+------------+-------------------+--------------+---------------------+--------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_schedule = df.withColumn(\"arrival_time\",remove_date_udf(df.arrival_time))\n",
    "df_schedule = df_schedule.withColumn(\"departure_time\",remove_date_udf(\"departure_time\"))\n",
    "df_schedule = df_schedule.withColumn(\"stop_dt_at\",struct(df_schedule.stop_name,df_schedule.arrival_time,df_schedule.departure_time))\n",
    "\n",
    "df_schedule.show(5,False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We now group all rows by trip ID to try to reconstruct the different trips**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group trips by Trip ID and collect all the itineraries\n",
    "df_grouped_trips = df_schedule.select([\"date\", \"trip_id\", \"stop_dt_at\"]) \\\n",
    "                              .groupBy([\"date\", \"trip_id\"]) \\\n",
    "                              .agg(F.collect_list(\"stop_dt_at\") \\\n",
    "                              .alias(\"stations\")) \\\n",
    "                              .groupBy(\"trip_id\") \\\n",
    "                              .agg(F.collect_list(\"stations\").alias(\"stations\"))\n",
    "#df_grouped_trips_week_day.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After grouping all the itineraries by trip ID, the next step is to build single typical journeys. We will start by removing duplicates.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(l):\n",
    "    \"\"\"This function removes duplicates from a given list \"\"\"\n",
    "    elements = []\n",
    "    for i in l:\n",
    "        if i not in elements:\n",
    "            elements.append(i)\n",
    "    return elements\n",
    "\n",
    "setudf = F.udf(remove_duplicates, ArrayType(ArrayType(StructType([\n",
    "                    StructField(\"stop_name\", StringType(), True),\n",
    "                    StructField(\"arrival_time\", StringType(), True),\n",
    "                    StructField(\"departure_time\", StringType(), True)\n",
    "                    ]))))\n",
    "trips = df_grouped_trips.withColumn(\"stations\", setudf(df_grouped_trips.stations)).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Row(stop_name='Dietlikon', arrival_time='06:43', departure_time='06:44'),\n",
       "  Row(stop_name='Stettbach', arrival_time='06:47', departure_time='06:48'),\n",
       "  Row(stop_name='Zürich Stadelhofen', arrival_time='06:52', departure_time='06:53'),\n",
       "  Row(stop_name='Zürich HB', arrival_time='06:56', departure_time='06:59'),\n",
       "  Row(stop_name='Zürich Hardbrücke', arrival_time='07:01', departure_time='07:01'),\n",
       "  Row(stop_name='Zürich Altstetten', arrival_time='07:05', departure_time='07:06'),\n",
       "  Row(stop_name='Schlieren', arrival_time='07:08', departure_time='07:08'),\n",
       "  Row(stop_name='Glanzenberg', arrival_time='07:10', departure_time='07:10')],\n",
       " [Row(stop_name='Dietlikon', arrival_time='06:43', departure_time='06:44'),\n",
       "  Row(stop_name='Stettbach', arrival_time='06:47', departure_time='06:48'),\n",
       "  Row(stop_name='Zürich Stadelhofen', arrival_time='06:52', departure_time='06:53')]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips['stations'][103]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We then transform the list of lists into list of tuples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_tuples(list_list):\n",
    "    \"\"\"This function transform a list of lists to a list of tuples\"\"\"\n",
    "    total_list = []\n",
    "    for l in list_list:\n",
    "        total_list.append([tuple(y) for y in l ])\n",
    "    return total_list\n",
    "\n",
    "trips[\"stations\"] = trips.stations.apply(transform_to_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Dietlikon', '06:43', '06:44'),\n",
       "  ('Stettbach', '06:47', '06:48'),\n",
       "  ('Zürich Stadelhofen', '06:52', '06:53'),\n",
       "  ('Zürich HB', '06:56', '06:59'),\n",
       "  ('Zürich Hardbrücke', '07:01', '07:01'),\n",
       "  ('Zürich Altstetten', '07:05', '07:06'),\n",
       "  ('Schlieren', '07:08', '07:08'),\n",
       "  ('Glanzenberg', '07:10', '07:10')],\n",
       " [('Dietlikon', '06:43', '06:44'),\n",
       "  ('Stettbach', '06:47', '06:48'),\n",
       "  ('Zürich Stadelhofen', '06:52', '06:53')]]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips['stations'][103]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To keep only a single itinerary, we keep the longest sublist of stops only. This gets more clear when looking at the example.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_only_longest(list_stations):\n",
    "    \"\"\" This function keeps the longest sublist of all the sublists of a given list\"\"\"\n",
    "    if len(list_stations) > 1:\n",
    "        if len(set([len(i) for i in list_stations])) > 1:\n",
    "            return sorted(list_stations, key=len, reverse=True)[0]\n",
    "        else:\n",
    "            nones = [ len([ x for i in l_tup for x in i if not x]) for l_tup in list_stations ]\n",
    "            return list_stations[np.argmin(nones)]\n",
    "    else:\n",
    "        return list_stations[0]\n",
    "    \n",
    "trips[\"stations\"] = trips[\"stations\"].apply(keep_only_longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dietlikon', '06:43', '06:44'),\n",
       " ('Stettbach', '06:47', '06:48'),\n",
       " ('Zürich Stadelhofen', '06:52', '06:53'),\n",
       " ('Zürich HB', '06:56', '06:59'),\n",
       " ('Zürich Hardbrücke', '07:01', '07:01'),\n",
       " ('Zürich Altstetten', '07:05', '07:06'),\n",
       " ('Schlieren', '07:08', '07:08'),\n",
       " ('Glanzenberg', '07:10', '07:10')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips['stations'][103]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the edges\n",
    "\n",
    "In the next cell, we will consider a new graph with nodes being the departure and arrival stations and the edge the connection between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of dictionaries containing the connections between stations\n",
    "\n",
    "edges = []\n",
    "\n",
    "for _, row in trips.iterrows():\n",
    "    t_id, stations = row\n",
    "    for i in range(len(stations) - 1):\n",
    "        start = stations[i]\n",
    "        arrival = stations[i + 1]\n",
    "        \n",
    "            #Name of the station of departure\n",
    "        departure_name = start[0]\n",
    "        \n",
    "        if start[-1] is not None:\n",
    "            departure_time = datetime.strptime(start[-1], \"%H:%M\")\n",
    "        else:\n",
    "            departure_time = None\n",
    "        \n",
    "        #Name of the station of arrival\n",
    "        arrival_name = arrival[0]\n",
    "        \n",
    "        if arrival[1] is not None:\n",
    "            arrival_time = datetime.strptime(arrival[1], \"%H:%M\")\n",
    "        else:\n",
    "            arrival_time = None\n",
    "        \n",
    "        if start[-1] is not None and arrival[1] is not None:\n",
    "            delta = int((arrival_time - departure_time).seconds/60)\n",
    "        else:\n",
    "            delta = None\n",
    "#         fill the array\n",
    "        edges.append({\"trip_id\":t_id,\n",
    "                      \"departure\":departure_name,\n",
    "                      \"departure_time\":departure_time,\n",
    "                      \"arrival\":arrival_name,\n",
    "                      \"arrival_time\":arrival_time,\n",
    "                      \"time\":delta})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>departure</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>arrival</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Dietlikon</td>\n",
       "      <td>1900-01-01 23:14:00</td>\n",
       "      <td>Stettbach</td>\n",
       "      <td>1900-01-01 23:17:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Stettbach</td>\n",
       "      <td>1900-01-01 23:18:00</td>\n",
       "      <td>Zürich Stadelhofen</td>\n",
       "      <td>1900-01-01 23:22:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Zürich Stadelhofen</td>\n",
       "      <td>1900-01-01 23:23:00</td>\n",
       "      <td>Zürich HB</td>\n",
       "      <td>1900-01-01 23:26:00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Zürich HB</td>\n",
       "      <td>1900-01-01 23:29:00</td>\n",
       "      <td>Zürich Hardbrücke</td>\n",
       "      <td>1900-01-01 23:31:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>Zürich Hardbrücke</td>\n",
       "      <td>1900-01-01 23:31:00</td>\n",
       "      <td>Zürich Altstetten</td>\n",
       "      <td>1900-01-01 23:35:00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           trip_id           departure      departure_time  \\\n",
       "0  85:11:18388:001           Dietlikon 1900-01-01 23:14:00   \n",
       "1  85:11:18388:001           Stettbach 1900-01-01 23:18:00   \n",
       "2  85:11:18388:001  Zürich Stadelhofen 1900-01-01 23:23:00   \n",
       "3  85:11:18388:001           Zürich HB 1900-01-01 23:29:00   \n",
       "4  85:11:18388:001   Zürich Hardbrücke 1900-01-01 23:31:00   \n",
       "\n",
       "              arrival        arrival_time  time  \n",
       "0           Stettbach 1900-01-01 23:17:00     3  \n",
       "1  Zürich Stadelhofen 1900-01-01 23:22:00     4  \n",
       "2           Zürich HB 1900-01-01 23:26:00     3  \n",
       "3   Zürich Hardbrücke 1900-01-01 23:31:00     2  \n",
       "4   Zürich Altstetten 1900-01-01 23:35:00     4  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop it into a pandas dataframe\n",
    "edges_df = pd.DataFrame(edges, columns=[\"trip_id\", \"departure\", \"departure_time\",\n",
    "                      \"arrival\", \"arrival_time\", \"time\"])\n",
    "edges_df = edges_df.dropna()\n",
    "edges_df = edges_df[edges_df.departure != edges_df.arrival]\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is to construct a dictionary of walking connection i.e if the distance between 2 stations is less than\n",
    "# DIST_THRESHOLD then no need to take another bus --> just walk\n",
    "\n",
    "DIST_THRESHOLD = 0.5 # in kilometers\n",
    "\n",
    "def time_to_walk(dist):\n",
    "    \"\"\"\n",
    "    Google Maps assumes a 5 kms an hour walking speed, \n",
    "    which is not that realistic for most people especially when you are new to an area \n",
    "    and keeping a lookout around you.\n",
    "\n",
    "    We will use 4km an hour \n",
    "    \"\"\"\n",
    "    \n",
    "    return np.ceil(dist * 60 / 4 )\n",
    "\n",
    "def get_name_coordinates(row):\n",
    "    name = row[\"name\"]\n",
    "    lat = row[\"lat\"]\n",
    "    long = row[\"long\"]\n",
    "    alt = row[\"altitude\"]\n",
    "    return name, (lat,long,alt)\n",
    "\n",
    "# init\n",
    "walking_connections = {}\n",
    "\n",
    "for _, row in coordinates.iterrows():\n",
    "    station,from_coords = get_name_coordinates(row)\n",
    "    station_dist = []\n",
    "    for _, row2 in coordinates.iterrows():\n",
    "        station2,to_coords = get_name_coordinates(row2)\n",
    "        if station != station2:\n",
    "            km_dist = distance.distance(from_coords,to_coords).km\n",
    "            if km_dist < DIST_THRESHOLD:\n",
    "                station_dist.append((station2, km_dist, time_to_walk(km_dist)))\n",
    "    walking_connections[station] = station_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now build a dataframe of all close stations (less than 500m) where we assume that the rider gains time by simply walking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_array_walk= []\n",
    "the_stations = set(edges_df.arrival).union(set(edges_df.departure))\n",
    "\n",
    "for from_station in  the_stations:\n",
    "    if from_station in walking_connections.keys():\n",
    "        connections = walking_connections[from_station]\n",
    "        for connection in connections:\n",
    "            # connection here is a tuple if the form (name_of_station, dist_to_stations, time_to_walk_to_station)\n",
    "            to_station = connection[0]\n",
    "            if to_station in the_stations:\n",
    "                row = [\"walk\", from_station, \"null\", to_station, \"null\", int(connection[2])]\n",
    "                df_array_walk.append(row)      \n",
    "        \n",
    "df_walk = pd.DataFrame(data = df_array_walk, columns = [\"trip_id\", \"departure\", \"departure_time\", \"arrival\", \"arrival_time\", \"time\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>departure</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>arrival</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>walk</td>\n",
       "      <td>Zürich Binz</td>\n",
       "      <td>null</td>\n",
       "      <td>Zürich Giesshübel</td>\n",
       "      <td>null</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>walk</td>\n",
       "      <td>Glattbrugg</td>\n",
       "      <td>null</td>\n",
       "      <td>Opfikon</td>\n",
       "      <td>null</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>walk</td>\n",
       "      <td>Opfikon</td>\n",
       "      <td>null</td>\n",
       "      <td>Glattbrugg</td>\n",
       "      <td>null</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>walk</td>\n",
       "      <td>Zürich Manegg</td>\n",
       "      <td>null</td>\n",
       "      <td>Zürich Leimbach</td>\n",
       "      <td>null</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>walk</td>\n",
       "      <td>Zürich Leimbach</td>\n",
       "      <td>null</td>\n",
       "      <td>Zürich Manegg</td>\n",
       "      <td>null</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trip_id        departure departure_time            arrival arrival_time  \\\n",
       "4    walk      Zürich Binz           null  Zürich Giesshübel         null   \n",
       "5    walk       Glattbrugg           null            Opfikon         null   \n",
       "0    walk          Opfikon           null         Glattbrugg         null   \n",
       "2    walk    Zürich Manegg           null    Zürich Leimbach         null   \n",
       "3    walk  Zürich Leimbach           null      Zürich Manegg         null   \n",
       "\n",
       "   time  \n",
       "4     4  \n",
       "5     4  \n",
       "0     4  \n",
       "2     7  \n",
       "3     7  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_walk.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routing Algorithm\n",
    "\n",
    "Our routing algorithm works as follows :\n",
    "\n",
    "    - The first step is to reduce the data by filtering out the nodes that are not reachable from Zurich. This is done by discovering the graph using bfs.\n",
    "    \n",
    "    - Next apply djisktra algorithm to find the shortest path starting from Zurich to the desired arrival_station\n",
    "\n",
    "The next cells contain the different implementations. We will then test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_addition(time, hours=0, minutes=0):\n",
    "    \"\"\"\n",
    "    time is a String that is of the format \"HH:MM\",\n",
    "    hours are the hours to add\n",
    "    minutes are the minutes to add\n",
    "    \n",
    "    Returns the time after addition\n",
    "    \"\"\"\n",
    "    return (datetime.strptime(time, \"%H:%M\") + timedelta(hours=hours, minutes=minutes)).strftime('%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighbours(node, time,edges_max_hours, t_id=None):\n",
    "    \"\"\"\n",
    "    This auxilary function returns the different reachable nodes from a given node starting from time\n",
    "    \n",
    "    \"\"\"\n",
    "    available = edges_max_hours[edges_max_hours.departure == node] \\\n",
    "                    .between_time(time, time_addition(time, minutes=waiting_time))\n",
    "    \n",
    "    walkable = df_walk[df_walk.departure == node]\n",
    "    for i, row in walkable.iterrows():\n",
    "\n",
    "        walk_time = row[\"time\"]\n",
    "        walkable.set_value(i,'departure_time', datetime.strptime(time, \"%H:%M\"))\n",
    "        walkable.set_value(i,'arrival_time', datetime.strptime(time_addition(time, minutes = walk_time), \"%H:%M\"))\n",
    "    \n",
    "    walkable.set_index(\"departure_time\", inplace=True)\n",
    "        \n",
    "    if t_id is not None:\n",
    "        \n",
    "        # We considered that two minutes are necessary when the rider has to change from means of transportation\n",
    "        t_id_time = time_addition(time, minutes=2)\n",
    "        \n",
    "        diff_t_id = available[available.trip_id != t_id].between_time(t_id_time, time_addition(t_id_time, minutes=waiting_time))\n",
    "        available = pd.concat([available[available.trip_id == t_id], diff_t_id, walkable])\n",
    "             \n",
    "    result = []\n",
    "    \n",
    "    for node in available.arrival.unique():\n",
    "        result.append(available[available.arrival == node].sort_values(\"arrival_time\").iloc[0])\n",
    "        \n",
    "    return sorted(result, key=lambda x: x.arrival_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(starting_station, query_time,edges_max_hours):\n",
    "    \"\"\"\n",
    "    Returns all reachable nodes of the graph from starting_station\n",
    "    \"\"\"\n",
    "    remaining_nodes = [(starting_station, query_time, None)]\n",
    "    \n",
    "    set_ = set()\n",
    "    edges = []\n",
    "    \n",
    "    while remaining_nodes:\n",
    "        \n",
    "        actual_node, query_time, t_id = remaining_nodes.pop(0)\n",
    "        \n",
    "        #Mark as visited\n",
    "        set_.update({actual_node})\n",
    "        \n",
    "        #Look for the set of reachable nodes from node\n",
    "        neighbors = neighbours(actual_node, query_time,edges_max_hours, t_id)\n",
    "        \n",
    "        for node in neighbors:\n",
    "            \n",
    "            if node.arrival not in set_:\n",
    "                edges.append(node)\n",
    "                remaining_nodes.append((node.arrival, node.arrival_time.strftime(\"%H:%M\"), node.trip_id))\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring delays\n",
    "\n",
    "The next step to build a robust model is to take into account the different departure and arrival delays of each of the trip_ids. Therefore, we computed their mean and used it to model the delay as a random variable following an exponential distribution. \n",
    "\n",
    "We also considered only trips happening during working days for the sake of simplicity. Only small changes are needed to test the model on a week end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+--------+-------+----------------+----------------+-------------------+----------------+---------------------+-------------+---------------+-------+\n",
      "|      date|       trip_id|train_id|  BPUIC|       stop_name|    arrival_time|actual_arrival_time|  departure_time|actual_departure_time|arrival_delay|departure_delay|weekend|\n",
      "+----------+--------------+--------+-------+----------------+----------------+-------------------+----------------+---------------------+-------------+---------------+-------+\n",
      "|20.04.2018|85:11:1255:001|    1255|8503000|       Zürich HB|20.04.2018 08:26|20.04.2018 08:27:41|20.04.2018 08:37|  20.04.2018 08:39:43|            2|              3|  false|\n",
      "|20.04.2018|85:11:1258:001|    1258|8503000|       Zürich HB|20.04.2018 21:23|20.04.2018 21:25:19|20.04.2018 21:34|  20.04.2018 21:34:51|            3|              1|  false|\n",
      "|20.04.2018|85:11:1507:002|    1507|8503000|       Zürich HB|20.04.2018 06:30|20.04.2018 06:30:14|20.04.2018 06:39|  20.04.2018 06:39:52|            1|              1|  false|\n",
      "|20.04.2018|85:11:1507:002|    1507|8503016|Zürich Flughafen|20.04.2018 06:49|20.04.2018 06:49:43|20.04.2018 06:51|  20.04.2018 06:52:01|            1|              2|  false|\n",
      "|20.04.2018|85:11:1509:003|    1509|8503000|       Zürich HB|20.04.2018 07:30|20.04.2018 07:31:24|20.04.2018 07:39|  20.04.2018 07:39:36|            2|              1|  false|\n",
      "|20.04.2018|85:11:1509:003|    1509|8503016|Zürich Flughafen|20.04.2018 07:49|20.04.2018 07:49:58|20.04.2018 07:51|  20.04.2018 07:52:15|            1|              2|  false|\n",
      "|20.04.2018|85:11:1510:003|    1510|8503016|Zürich Flughafen|20.04.2018 07:11|20.04.2018 07:11:00|20.04.2018 07:13|  20.04.2018 07:13:42|            0|              1|  false|\n",
      "|20.04.2018|85:11:1510:003|    1510|8503000|       Zürich HB|20.04.2018 07:23|20.04.2018 07:21:22|20.04.2018 07:30|  20.04.2018 07:30:34|            0|              1|  false|\n",
      "|20.04.2018|85:11:1511:003|    1511|8503000|       Zürich HB|20.04.2018 08:30|20.04.2018 08:31:06|20.04.2018 08:39|  20.04.2018 08:39:33|            2|              1|  false|\n",
      "|20.04.2018|85:11:1511:003|    1511|8503016|Zürich Flughafen|20.04.2018 08:49|20.04.2018 08:49:19|20.04.2018 08:51|  20.04.2018 08:52:01|            1|              2|  false|\n",
      "|20.04.2018|85:11:1512:003|    1512|8503016|Zürich Flughafen|20.04.2018 08:11|20.04.2018 08:12:18|20.04.2018 08:13|  20.04.2018 08:15:23|            2|              3|  false|\n",
      "|20.04.2018|85:11:1512:003|    1512|8503000|       Zürich HB|20.04.2018 08:23|20.04.2018 08:23:22|20.04.2018 08:30|  20.04.2018 08:30:33|            1|              1|  false|\n",
      "|20.04.2018|85:11:1513:003|    1513|8503000|       Zürich HB|20.04.2018 09:30|20.04.2018 09:31:07|20.04.2018 09:39|  20.04.2018 09:39:47|            2|              1|  false|\n",
      "|20.04.2018|85:11:1513:003|    1513|8503016|Zürich Flughafen|20.04.2018 09:49|20.04.2018 09:49:55|20.04.2018 09:51|  20.04.2018 09:55:45|            1|              5|  false|\n",
      "|20.04.2018|85:11:1514:003|    1514|8503016|Zürich Flughafen|20.04.2018 09:11|20.04.2018 09:10:33|20.04.2018 09:13|  20.04.2018 09:14:28|            0|              2|  false|\n",
      "|20.04.2018|85:11:1514:003|    1514|8503000|       Zürich HB|20.04.2018 09:23|20.04.2018 09:22:22|20.04.2018 09:30|  20.04.2018 09:30:55|            0|              1|  false|\n",
      "|20.04.2018|85:11:1515:003|    1515|8503000|       Zürich HB|20.04.2018 10:30|20.04.2018 10:31:58|20.04.2018 10:39|  20.04.2018 10:39:24|            2|              1|  false|\n",
      "|20.04.2018|85:11:1515:003|    1515|8503016|Zürich Flughafen|20.04.2018 10:49|20.04.2018 10:50:20|20.04.2018 10:51|  20.04.2018 10:52:28|            2|              2|  false|\n",
      "|20.04.2018|85:11:1516:001|    1516|8503016|Zürich Flughafen|20.04.2018 10:11|20.04.2018 10:10:40|20.04.2018 10:13|  20.04.2018 10:14:56|            0|              2|  false|\n",
      "|20.04.2018|85:11:1516:001|    1516|8503000|       Zürich HB|20.04.2018 10:23|20.04.2018 10:22:43|20.04.2018 10:30|  20.04.2018 10:31:05|            0|              2|  false|\n",
      "+----------+--------------+--------+-------+----------------+----------------+-------------------+----------------+---------------------+-------------+---------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def add_zeros(date):\n",
    "    \"\"\"\n",
    "    Adds the :00 as seconds\n",
    "    \"\"\"\n",
    "    result = date\n",
    "    split_date = date.split(':')\n",
    "    if len(split_date) == 2:\n",
    "        result += ':00'\n",
    "    return result\n",
    "\n",
    "def calc_time_difference(actual_time, scheduled_time):\n",
    "    \"\"\"\n",
    "    Calculates the time difference between actual and scheduled times \n",
    "    \n",
    "    \"\"\"\n",
    "    #Check the times are non empty\n",
    "    if actual_time != \"null\" and scheduled_time != \"null\" :\n",
    "    \n",
    "      if (isinstance(actual_time, str) and isinstance(scheduled_time, str)):\n",
    "            actual = add_zeros(actual_time)\n",
    "            time_actual = datetime.strptime(actual, \"%d.%m.%Y %H:%M:%S\")\n",
    "\n",
    "            scheduled = add_zeros(scheduled_time)\n",
    "            time_scheduled = datetime.strptime(scheduled, \"%d.%m.%Y %H:%M:%S\")\n",
    "          \n",
    "            # Add one minute if number of seconds is non null \n",
    "            if time_actual.second != 0:\n",
    "                time_actual = time_actual + timedelta(seconds = 60 - time_actual.second)\n",
    "\n",
    "            if time_scheduled.second != 0:\n",
    "                time_scheduled = time_schedule + timedelta(seconds = 60 - time_scheduled.second)\n",
    "\n",
    "            if time_actual > time_scheduled:\n",
    "                delta = time_actual - time_scheduled\n",
    "                return int(delta.seconds / 60)\n",
    "            else:\n",
    "                return 0\n",
    "    else: \n",
    "        return None\n",
    "    \n",
    "calc_time_difference_udf = udf(lambda row: calc_time_difference(row[0], row[1]), IntegerType())\n",
    "\n",
    "df_delays = df.withColumn(\"arrival_delay\", calc_time_difference_udf(struct([df['actual_arrival_time'], df['arrival_time']])))\n",
    "df_delays = df_delays.withColumn(\"departure_delay\", calc_time_difference_udf(struct([df['actual_departure_time'], df['departure_time']])))\n",
    "\n",
    "#Add a column weekend to know if the trip is happening on a workin day or on week ends\n",
    "is_weekend = udf(lambda row: True if datetime.strptime(row, \"%d.%m.%Y\").weekday() in [5,6] else False)\n",
    "df_delays = df_delays.withColumn(\"weekend\", is_weekend(df_delays[\"date\"]))\n",
    "\n",
    "# For the sake of simplicity we will only consider the trips happening during a workin day\n",
    "df_delays = df_delays.filter(df_delays.weekend == False)\n",
    "df_delays.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>mean_departure</th>\n",
       "      <th>mean_arrival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85:11:18388:001</td>\n",
       "      <td>2.1595092024539877</td>\n",
       "      <td>1.3987730061349692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85:11:18718:001</td>\n",
       "      <td>1.7797619047619047</td>\n",
       "      <td>1.1130952380952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85:11:18982:002</td>\n",
       "      <td>1.6402116402116402</td>\n",
       "      <td>1.0582010582010581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>85:11:19439:001</td>\n",
       "      <td>1.8666666666666667</td>\n",
       "      <td>1.3714285714285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85:11:19526:001</td>\n",
       "      <td>2.3278688524590163</td>\n",
       "      <td>1.9918032786885247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           trip_id      mean_departure        mean_arrival\n",
       "0  85:11:18388:001  2.1595092024539877  1.3987730061349692\n",
       "1  85:11:18718:001  1.7797619047619047  1.1130952380952381\n",
       "2  85:11:18982:002  1.6402116402116402  1.0582010582010581\n",
       "3  85:11:19439:001  1.8666666666666667  1.3714285714285714\n",
       "4  85:11:19526:001  2.3278688524590163  1.9918032786885247"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_mean_delay(list_delays):\n",
    "    \"\"\"\n",
    "    Compute the mean of the delays of a list of delays\n",
    "    \"\"\"\n",
    "    if isinstance(list_delays, (list,)):\n",
    "        if len(list_delays) == 0:\n",
    "            return 0.0\n",
    "        else:\n",
    "            delay = np.mean(list_delays)\n",
    "            return float(delay)\n",
    "    elif isinstance(list_delays, (int,)):\n",
    "        return float(list_delays)\n",
    "    else:\n",
    "        return 0.0\n",
    "    \n",
    "compute_mean_delay_udf= udf(lambda row: compute_mean_delay(row))\n",
    "\n",
    "#Group the delays by Trip ID and compute the mean delay of departure and arrival of each of them\n",
    "dep_arr_delays = df_delays.groupBy(\"trip_id\") \\\n",
    "                            .agg(F.collect_list(\"departure_delay\").alias(\"list_departures\"),\n",
    "                                 F.collect_list(\"arrival_delay\").alias(\"list_arrivals\"))\n",
    "dep_arr_delays = dep_arr_delays.withColumn(\"mean_departure\", compute_mean_delay_udf(dep_arr_delays[\"list_departures\"])) \\\n",
    "                                   .withColumn(\"mean_arrival\", compute_mean_delay_udf(dep_arr_delays[\"list_arrivals\"]))\n",
    "\n",
    "trip_delays = dep_arr_delays.select([\"trip_id\", \"mean_departure\", \"mean_arrival\"]).toPandas()\n",
    "\n",
    "#We consider no delays when walking\n",
    "trip_delays = trip_delays.append({'trip_id':\"walk\",'mean_departure':0.0,'mean_arrival':0.0},ignore_index=True)\n",
    "\n",
    "trip_delays.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query_time = \"12:00\"\n",
    "waiting_time = 15\n",
    "starting_station = \"Zürich HB\"\n",
    "arrival_station = \"Dübendorf\"\n",
    "MAX_HOURS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find reachable nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>departure_time</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>departure</th>\n",
       "      <th>arrival</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1900-01-01 12:00:00</td>\n",
       "      <td>85:11:18643:001</td>\n",
       "      <td>Zürich HB</td>\n",
       "      <td>Zürich Stadelhofen</td>\n",
       "      <td>1900-01-01 12:02:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900-01-01 12:01:00</td>\n",
       "      <td>85:11:18644:001</td>\n",
       "      <td>Zürich HB</td>\n",
       "      <td>Zürich Hardbrücke</td>\n",
       "      <td>1900-01-01 12:03:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1900-01-01 12:03:00</td>\n",
       "      <td>85:11:18643:001</td>\n",
       "      <td>Zürich Stadelhofen</td>\n",
       "      <td>Zürich Tiefenbrunnen</td>\n",
       "      <td>1900-01-01 12:05:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1900-01-01 12:01:00</td>\n",
       "      <td>85:11:2640:001</td>\n",
       "      <td>Zürich HB</td>\n",
       "      <td>Zürich Oerlikon</td>\n",
       "      <td>1900-01-01 12:07:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1900-01-01 12:06:00</td>\n",
       "      <td>85:11:18643:001</td>\n",
       "      <td>Zürich Tiefenbrunnen</td>\n",
       "      <td>Zollikon</td>\n",
       "      <td>1900-01-01 12:08:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       departure_time          trip_id             departure  \\\n",
       "0 1900-01-01 12:00:00  85:11:18643:001             Zürich HB   \n",
       "1 1900-01-01 12:01:00  85:11:18644:001             Zürich HB   \n",
       "2 1900-01-01 12:03:00  85:11:18643:001    Zürich Stadelhofen   \n",
       "3 1900-01-01 12:01:00   85:11:2640:001             Zürich HB   \n",
       "4 1900-01-01 12:06:00  85:11:18643:001  Zürich Tiefenbrunnen   \n",
       "\n",
       "                arrival        arrival_time  time  \n",
       "0    Zürich Stadelhofen 1900-01-01 12:02:00     2  \n",
       "1     Zürich Hardbrücke 1900-01-01 12:03:00     2  \n",
       "2  Zürich Tiefenbrunnen 1900-01-01 12:05:00     2  \n",
       "3       Zürich Oerlikon 1900-01-01 12:07:00     6  \n",
       "4              Zollikon 1900-01-01 12:08:00     2  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "edges_max_hours = edges_df.set_index(\"departure_time\") \\\n",
    "                      .between_time(query_time, time_addition(query_time, hours=MAX_HOURS)) \\\n",
    "                      .sort_index()\n",
    "\n",
    "reachable_nodes = bfs(starting_station, query_time,edges_max_hours)\n",
    "\n",
    "edges = pd.DataFrame(reachable_nodes).drop_duplicates()\n",
    "edges = edges.sort_values(\"arrival_time\")[~edges.sort_values(\"arrival_time\").duplicated([\"arrival\", \"departure\"])]\n",
    "edges = edges.reset_index().rename(columns={'index':'departure_time'})\n",
    "edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find shortest path to destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for i in range(len(edges)):\n",
    "    entry = edges.iloc[i]\n",
    "    node_in = entry.departure\n",
    "    node_out = entry.arrival\n",
    "    if (trip_delays[trip_delays.trip_id == entry.trip_id].shape[0] != 0):\n",
    "        the_lambda = float(trip_delays[trip_delays.trip_id == entry.trip_id].mean_arrival)\n",
    "    \n",
    "    kind = 'train'\n",
    "    if (entry.trip_id =='walk'):\n",
    "        kind = 'walk'\n",
    "    G.add_edge(node_in,node_out, weight = entry.time, departure = entry.departure_time, arrival = entry.arrival_time, lambda_ = the_lambda ,kind=kind,train =entry.trip_id )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeView(('Zürich HB', 'Zürich Stadelhofen', 'Zürich Hardbrücke', 'Zürich Tiefenbrunnen', 'Zürich Oerlikon', 'Zollikon', 'Zürich Wiedikon', 'Küsnacht Goldbach', 'Stettbach', 'Zürich Seebach', 'Küsnacht ZH', 'Zürich Enge', 'Dietlikon', 'Thalwil', 'Zürich Altstetten', 'Zürich Affoltern', 'Zürich Wollishofen', 'Erlenbach ZH', 'Zürich Flughafen', 'Kilchberg', 'Glattbrugg', 'Zürich Wipkingen', 'Urdorf', 'Regensdorf-Watt', 'Rümlang', 'Wallisellen', 'Urdorf Weihermatt', 'Opfikon', 'Schlieren', 'Rüschlikon', 'Dübendorf', 'Birmensdorf ZH', 'Glanzenberg', 'Schwerzenbach ZH', 'Bonstetten-Wettswil', 'Bassersdorf', 'Kloten Balsberg', 'Kloten'))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = list(nx.shortest_path(G,source='Zürich HB',target='Regensdorf-Watt',weight='weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zürich HB',\n",
       " 'Zürich Oerlikon',\n",
       " 'Zürich Seebach',\n",
       " 'Zürich Affoltern',\n",
       " 'Regensdorf-Watt']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model the distribution of delays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CDFExponential(lamb,x): #lamb = lambda\n",
    "    if x<=0:\n",
    "        cdf=0\n",
    "    else:\n",
    "        cdf=1-np.exp(-lamb*x)\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probability(time_difference,kind,lamb,train_id_arrival,train_id_departure):\n",
    "    if((kind == 'walk') or (train_id_arrival == train_id_departure)):\n",
    "        return 1\n",
    "    else:\n",
    "        return CDFExponential(lamb,time_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_robustness (array_probas):\n",
    "    return (1/m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start at Zürich HB at time 12:00\n",
      "--------------------\n",
      "train from Zürich HB at 12:01:00 arrives in Zürich Oerlikon at 12:07:00 85:11:2640:001 with probability 1\n",
      "--------------------\n",
      "train from Zürich Oerlikon at 12:09:00 arrives in Zürich Seebach at 12:11:00 85:11:18644:001 with probability 0.8309866845939339\n",
      "--------------------\n",
      "train from Zürich Seebach at 12:11:00 arrives in Zürich Affoltern at 12:14:00 85:11:18644:001 with probability 1\n",
      "--------------------\n",
      "train from Zürich Affoltern at 12:14:00 arrives in Regensdorf-Watt at 12:18:00 85:11:18644:001 with probability 1\n",
      "--------------------\n",
      "Robustness of this journey is 0.8309866845939339\n"
     ]
    }
   ],
   "source": [
    "print('start at '+ 'Zürich HB ' + 'at time '+ query_time)\n",
    "probabilities = []\n",
    "for i in range(len(path)-1) :\n",
    "    print('-'*20)\n",
    "#     The time difference between the arrival of this train and the departure of the next\n",
    "    probability = 1\n",
    "    if (i == 0):\n",
    "        actual_metadata = G.get_edge_data(path[i],path[i+1])\n",
    "    if i >0 :\n",
    "        previous_metadata = actual_metadata\n",
    "        actual_metadata = G.get_edge_data(path[i],path[i+1])\n",
    "        \n",
    "        time_difference = (actual_metadata['departure'] - previous_metadata['arrival']).seconds //60\n",
    "#         Compute lambda \n",
    "        lamb = 1/(previous_metadata['lambda_']*0.5 + actual_metadata['lambda_']*0.5)\n",
    "#         Get the probability\n",
    "        probability = compute_probability(time_difference,actual_metadata['kind'],lamb,previous_metadata['train'],actual_metadata['train'])\n",
    "    \n",
    "    probabilities.append( probability)\n",
    "    print(actual_metadata['kind'] +' from '+path[i]+ ' at '+ actual_metadata['departure'].strftime('%Y-%m-%d %H:%M:%S')[11:] + ' arrives in '+ path[i+1]+' at '+ actual_metadata['arrival'].strftime('%Y-%m-%d %H:%M:%S')[11:] +' ' +actual_metadata['train'] +' with probability '+str(probability))\n",
    "    \n",
    "robustness = np.min(probabilities)\n",
    "print('-'*20)\n",
    "print('Robustness of this journey is ' + str(robustness))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization on a map\n",
    "\n",
    "The last step of our work is a visualisation of the itinerary on a follium map. It perfectly fits with google maps' one with the difference that our journey planner is more robust as it gives probabilites of missing connections as seen above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><iframe src=\"data:text/html;charset=utf-8;base64,<!DOCTYPE html>
<head>    
    <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
    
        <script>
            L_NO_TOUCH = false;
            L_DISABLE_3D = false;
        </script>
    
    <script src="https://cdn.jsdelivr.net/npm/leaflet@1.4.0/dist/leaflet.js"></script>
    <script src="https://code.jquery.com/jquery-1.12.4.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.4.0/dist/leaflet.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css"/>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css"/>
    <link rel="stylesheet" href="https://rawcdn.githack.com/python-visualization/folium/master/folium/templates/leaflet.awesome.rotate.css"/>
    <style>html, body {width: 100%;height: 100%;margin: 0;padding: 0;}</style>
    <style>#map {position:absolute;top:0;bottom:0;right:0;left:0;}</style>
    
            <meta name="viewport" content="width=device-width,
                initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
            <style>
                #map_3d404e8d3c8744dab829355c2d9e61da {
                    position: relative;
                    width: 100.0%;
                    height: 100.0%;
                    left: 0.0%;
                    top: 0.0%;
                }
            </style>
        
</head>
<body>    
    
            <div class="folium-map" id="map_3d404e8d3c8744dab829355c2d9e61da" ></div>
        
</body>
<script>    
    
            var map_3d404e8d3c8744dab829355c2d9e61da = L.map(
                "map_3d404e8d3c8744dab829355c2d9e61da",
                {
                    center: [47.418747, 8.544636],
                    crs: L.CRS.EPSG3857,
                    zoom: 12,
                    zoomControl: true,
                    preferCanvas: false,
                }
            );

            

        
    
            var tile_layer_409f172d806c40a599d6536612c820fa = L.tileLayer(
                "https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png",
                {"attribution": "Data by \u0026copy; \u003ca href=\"http://openstreetmap.org\"\u003eOpenStreetMap\u003c/a\u003e, under \u003ca href=\"http://www.openstreetmap.org/copyright\"\u003eODbL\u003c/a\u003e.", "detectRetina": false, "maxNativeZoom": 18, "maxZoom": 18, "minZoom": 0, "noWrap": false, "opacity": 1, "subdomains": "abc", "tms": false}
            ).addTo(map_3d404e8d3c8744dab829355c2d9e61da);
        
    
            var marker_85851bf2bbec43cf9e14847f94a984cb = L.marker(
                [47.378177, 8.540192],
                {}
            ).addTo(map_3d404e8d3c8744dab829355c2d9e61da);
        
    
        var popup_78a5ef8c452546e9a550b2d67aca8e72 = L.popup({"maxWidth": "100%"});

        
            var html_2f594eedf0044746a1bcbc4ee4ba9e76 = $(`<div id="html_2f594eedf0044746a1bcbc4ee4ba9e76" style="width: 100.0%; height: 100.0%;">Zürich HB</div>`)[0];
            popup_78a5ef8c452546e9a550b2d67aca8e72.setContent(html_2f594eedf0044746a1bcbc4ee4ba9e76);
        

        marker_85851bf2bbec43cf9e14847f94a984cb.bindPopup(popup_78a5ef8c452546e9a550b2d67aca8e72)
        ;

        
    
    
            var marker_2fccb8b6026c4197baf4b9e92cb6ddfd = L.marker(
                [47.411529, 8.544115],
                {}
            ).addTo(map_3d404e8d3c8744dab829355c2d9e61da);
        
    
        var popup_00b8177205394af18a916b66606618e5 = L.popup({"maxWidth": "100%"});

        
            var html_57a7a2db9d3844ce939342b05aa644e3 = $(`<div id="html_57a7a2db9d3844ce939342b05aa644e3" style="width: 100.0%; height: 100.0%;">Zürich Oerlikon</div>`)[0];
            popup_00b8177205394af18a916b66606618e5.setContent(html_57a7a2db9d3844ce939342b05aa644e3);
        

        marker_2fccb8b6026c4197baf4b9e92cb6ddfd.bindPopup(popup_00b8177205394af18a916b66606618e5)
        ;

        
    
    
            var marker_74beb8d1b1164fbbb1fcf14ec032a54d = L.marker(
                [47.418747, 8.544636],
                {}
            ).addTo(map_3d404e8d3c8744dab829355c2d9e61da);
        
    
        var popup_207b92bf354b4a0598c8da35867df76d = L.popup({"maxWidth": "100%"});

        
            var html_5a0b43a3e3f44d53b07f49499210648c = $(`<div id="html_5a0b43a3e3f44d53b07f49499210648c" style="width: 100.0%; height: 100.0%;">Zürich Seebach</div>`)[0];
            popup_207b92bf354b4a0598c8da35867df76d.setContent(html_5a0b43a3e3f44d53b07f49499210648c);
        

        marker_74beb8d1b1164fbbb1fcf14ec032a54d.bindPopup(popup_207b92bf354b4a0598c8da35867df76d)
        ;

        
    
    
            var marker_8f108fdeb96e471c970e14dbafbc55e4 = L.marker(
                [47.420913, 8.508565],
                {}
            ).addTo(map_3d404e8d3c8744dab829355c2d9e61da);
        
    
        var popup_28f3b00f43124656bbf628a77a6b7964 = L.popup({"maxWidth": "100%"});

        
            var html_b42476c969d949d3bc6668d2a0ecc556 = $(`<div id="html_b42476c969d949d3bc6668d2a0ecc556" style="width: 100.0%; height: 100.0%;">Zürich Affoltern</div>`)[0];
            popup_28f3b00f43124656bbf628a77a6b7964.setContent(html_b42476c969d949d3bc6668d2a0ecc556);
        

        marker_8f108fdeb96e471c970e14dbafbc55e4.bindPopup(popup_28f3b00f43124656bbf628a77a6b7964)
        ;

        
    
    
            var marker_2efabc0809ae493fa4c5d7573ec2ad12 = L.marker(
                [47.436563, 8.472064],
                {}
            ).addTo(map_3d404e8d3c8744dab829355c2d9e61da);
        
    
        var popup_06fed5deab744999ac928e7b6d827e75 = L.popup({"maxWidth": "100%"});

        
            var html_4ebdba019794411a99e3e287f4b32530 = $(`<div id="html_4ebdba019794411a99e3e287f4b32530" style="width: 100.0%; height: 100.0%;">Regensdorf-Watt</div>`)[0];
            popup_06fed5deab744999ac928e7b6d827e75.setContent(html_4ebdba019794411a99e3e287f4b32530);
        

        marker_2efabc0809ae493fa4c5d7573ec2ad12.bindPopup(popup_06fed5deab744999ac928e7b6d827e75)
        ;

        
    
    
            var poly_line_ab4e0b2c912b4ac6ad57b022e3fe7e2e = L.polyline(
                [[47.378177, 8.540192], [47.411529, 8.544115], [47.418747, 8.544636], [47.420913, 8.508565], [47.436563, 8.472064]],
                {"bubblingMouseEvents": true, "color": "red", "dashArray": null, "dashOffset": null, "fill": false, "fillColor": "red", "fillOpacity": 0.2, "fillRule": "evenodd", "lineCap": "round", "lineJoin": "round", "noClip": false, "opacity": 1, "smoothFactor": 1.0, "stroke": true, "weight": 2.5}
            ).addTo(map_3d404e8d3c8744dab829355c2d9e61da);
        
</script>\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7fd944718588>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import folium\n",
    "\n",
    "departure = coordinates[coordinates['name']==path[len(path)//2]][['lat','long']]\n",
    "m = folium.Map(location=departure, zoom_start=12)\n",
    "\n",
    "#Change list of stops by the output of Sami\n",
    "stops = coordinates[coordinates['name'].isin(path)][['name','lat','long']]\n",
    "stops_info = np.array(stops[['name','lat','long']])\n",
    "for i, info in enumerate(stops_info):\n",
    "    folium.Marker(\n",
    "        location=[info[1], info[2]],\n",
    "        popup=info[0]).add_to(m)\n",
    "    \n",
    "#add lines\n",
    "points = [(elem[1],elem[2]) for elem in stops_info]\n",
    "folium.PolyLine(points, color=\"red\", weight=2.5, opacity=1).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
